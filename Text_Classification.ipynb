{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {'knn': KNeighborsClassifier(), 'nb': MultinomialNB(), 'sgdc': SGDClassifier()}\n",
    "features = {'counts': None, 'tf': TfidfTransformer(use_idf=False), 'tfidf': TfidfTransformer()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets of parameters for Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "            {\n",
    "                'vect__lowercase': (True, False),\n",
    "            },\n",
    "            {\n",
    "                'vect__stop_words': (None, 'english'),\n",
    "            },\n",
    "            {\n",
    "                'vect__analyzer': ['word'],\n",
    "                'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            },\n",
    "            {\n",
    "                'vect__analyzer': ['char'],\n",
    "                'vect__ngram_range': [(2, 2), (3, 3), (4, 4)]\n",
    "            },\n",
    "            {\n",
    "                'vect__max_features': (1000, 5000, 10000)\n",
    "            }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_root_knn = int(np.sqrt(len(twenty_train.data)))\n",
    "half_root_knn = int(doc_root_knn / 2)\n",
    "hyperparameters = {\n",
    "                  \"knn\": {\n",
    "                              \"clf__n_neighbors\": [5, 11, 21, half_root_knn, doc_root_knn]\n",
    "                        },\n",
    "                  \"nb\": {\n",
    "                              \"clf__alpha\": [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "                        },\n",
    "                  \"sgdc\": {\n",
    "                              \"clf__alpha\": [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "                          }\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinations of pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipelines(classifiers: dict, features: dict):\n",
    "    pipelines = {}\n",
    "    for clf_key in classifiers.keys():\n",
    "        for feat_key in features.keys():\n",
    "            clf = classifiers.get(clf_key)\n",
    "            feat = features.get(feat_key)\n",
    "            pipe = Pipeline([\n",
    "                            ('vect', CountVectorizer()),\n",
    "                            ('tfidf', feat),\n",
    "                            ('clf', clf)\n",
    "            ])\n",
    "            pipelines[(clf_key, feat_key)] = pipe\n",
    "    return pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = build_pipelines(classifiers=classifiers, features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Experiment\n",
    "Test with all the default settings, each classifier with each of the parameters. No parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:48<00:00,  5.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Features  Mean Accuracy  Precision  Recall     F1\n",
       "0        knn   counts          0.352      0.421   0.352  0.357\n",
       "1        knn       tf          0.408      0.489   0.408  0.417\n",
       "2        knn    tfidf          0.659      0.674   0.659  0.660\n",
       "3         nb   counts          0.773      0.762   0.773  0.751\n",
       "4         nb       tf          0.705      0.785   0.705  0.692\n",
       "5         nb    tfidf          0.774      0.822   0.774  0.768\n",
       "6       sgdc   counts          0.758      0.784   0.758  0.759\n",
       "7       sgdc       tf          0.808      0.813   0.808  0.804\n",
       "8       sgdc    tfidf          0.852      0.853   0.852  0.850"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean_acc = []\n",
    "all_prf = []\n",
    "all_conf = []\n",
    "classifiers = []\n",
    "features = []\n",
    "\n",
    "for key, pipe in tqdm(pipelines.items()):\n",
    "    pipe.fit(twenty_train.data, twenty_train.target)\n",
    "    predicted = pipe.predict(twenty_test.data)\n",
    "\n",
    "    # mean accuracy\n",
    "    mean_acc = np.mean(predicted == twenty_test.target)\n",
    "    all_mean_acc.append(mean_acc)\n",
    "\n",
    "    # precision, recall, f1 score\n",
    "    prf = metrics.precision_recall_fscore_support(twenty_test.target, predicted, average='weighted')\n",
    "    all_prf.append(prf)\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(twenty_test.target, predicted)\n",
    "    all_conf.append(conf_matrix)\n",
    "\n",
    "    classifiers.append(key[0])\n",
    "    features.append(key[1])\n",
    "\n",
    "df_data = {\"Classifier\": classifiers,\n",
    "            \"Features\": features,\n",
    "            \"Mean Accuracy\": all_mean_acc\n",
    "          }\n",
    "results = pd.DataFrame(df_data)\n",
    "prf_df = pd.DataFrame(all_prf, columns=[\"Precision\", \"Recall\", \"F1\", \"_\"]).drop(columns=['_'])\n",
    "results = results.merge(prf_df, left_index=True, right_index=True)\n",
    "results = results.round(3)\n",
    "results.to_csv('results/experiment_default_knn.csv', index=False)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning on Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [02:39<00:00, 17.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'clf__n_neighbors': 5}</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'clf__n_neighbors': 5}</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'clf__n_neighbors': 5}</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'clf__alpha': 0.0001}</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'clf__alpha': 0.001}</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'clf__alpha': 0.01}</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'clf__alpha': 0.01}</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'clf__alpha': 0.0001}</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'clf__alpha': 0.0001}</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier Features          Best Parameters  Mean Accuracy  Precision  \\\n",
       "0        knn   counts  {'clf__n_neighbors': 5}          0.352      0.421   \n",
       "1        knn       tf  {'clf__n_neighbors': 5}          0.408      0.489   \n",
       "2        knn    tfidf  {'clf__n_neighbors': 5}          0.659      0.674   \n",
       "3         nb   counts   {'clf__alpha': 0.0001}          0.797      0.804   \n",
       "4         nb       tf    {'clf__alpha': 0.001}          0.833      0.834   \n",
       "5         nb    tfidf     {'clf__alpha': 0.01}          0.835      0.836   \n",
       "6       sgdc   counts     {'clf__alpha': 0.01}          0.794      0.803   \n",
       "7       sgdc       tf   {'clf__alpha': 0.0001}          0.811      0.811   \n",
       "8       sgdc    tfidf   {'clf__alpha': 0.0001}          0.853      0.854   \n",
       "\n",
       "   Recall     F1  \n",
       "0   0.352  0.357  \n",
       "1   0.408  0.417  \n",
       "2   0.659  0.660  \n",
       "3   0.797  0.785  \n",
       "4   0.833  0.831  \n",
       "5   0.835  0.834  \n",
       "6   0.794  0.788  \n",
       "7   0.811  0.806  \n",
       "8   0.853  0.852  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean_acc = []\n",
    "all_prf_hyper = []\n",
    "best_pipelines = {}\n",
    "best_params = []\n",
    "classifier_names = []\n",
    "feature_names = []\n",
    "all_cv_results = []\n",
    "for key, pipe in tqdm(pipelines.items()):\n",
    "    parameter_set = hyperparameters[key[0]]\n",
    "\n",
    "    gs_clf = GridSearchCV(pipe, parameter_set, cv=5, n_jobs=-1)\n",
    "    gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "    predicted = gs_clf.predict(twenty_test.data)\n",
    "\n",
    "    all_cv_results.append(gs_clf.cv_results_)\n",
    "    \n",
    "    mean_acc = np.mean(predicted == twenty_test.target)\n",
    "    all_mean_acc.append(mean_acc)\n",
    "    prf = metrics.precision_recall_fscore_support(twenty_test.target, predicted, average='weighted')\n",
    "    all_prf_hyper.append(prf)\n",
    "\n",
    "    best_estimator = gs_clf.best_estimator_\n",
    "    best_pipelines[key] = best_estimator\n",
    "    # best_pipelines.append(best_estimator)\n",
    "\n",
    "    best_param = gs_clf.best_params_\n",
    "    best_params.append(best_param)\n",
    "\n",
    "    classifier_names.append(key[0])\n",
    "    feature_names.append(key[1])\n",
    "    \n",
    "df_data = {\"Classifier\": classifier_names,\n",
    "    \"Features\": feature_names,\n",
    "    \"Best Parameters\": best_params,\n",
    "    \"Mean Accuracy\": all_mean_acc\n",
    "    }\n",
    "results_exp2 = pd.DataFrame(df_data)\n",
    "prf_hyper_df = pd.DataFrame(all_prf_hyper, columns=[\"Precision\", \"Recall\", \"F1\", \"_\"]).drop(columns=['_'])\n",
    "results_exp2 = results_exp2.merge(prf_hyper_df, left_index=True, right_index=True)\n",
    "results_exp2 = results_exp2.round(3)\n",
    "results_exp2.to_csv('results/experiment2_knn.csv')\n",
    "results_exp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Experiment: Vectorizer Parameters\n",
    "Uses best estimators from previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [05:16<18:27, 158.22s/it]/Users/andreassavva/opt/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      " 89%|████████▉ | 8/9 [16:53<02:00, 120.32s/it]/Users/andreassavva/opt/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 9/9 [18:59<00:00, 126.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Features</th>\n",
       "      <th>Vectorizer Parameters</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__lowercase': True}</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__lowercase': True}</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__lowercase': False}</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knn</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__lowercase': False}</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nb</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__lowercase': True}</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>nb</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__lowercase': False}</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__stop_words': None}</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>nb</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__lowercase': True}</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>counts</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__lowercase': False}</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__stop_words': 'english'}</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tf</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__lowercase': True}</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__stop_words': None}</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__analyzer': 'word', 'vect__ngram_range'...</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__analyzer': 'char', 'vect__ngram_range'...</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>sgdc</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>{'vect__max_features': 10000}</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier Features                              Vectorizer Parameters  \\\n",
       "0         knn   counts                          {'vect__lowercase': True}   \n",
       "1         knn   counts                    {'vect__stop_words': 'english'}   \n",
       "2         knn   counts  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "3         knn   counts  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "4         knn   counts                      {'vect__max_features': 10000}   \n",
       "5         knn       tf                          {'vect__lowercase': True}   \n",
       "6         knn       tf                    {'vect__stop_words': 'english'}   \n",
       "7         knn       tf  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "8         knn       tf  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "9         knn       tf                      {'vect__max_features': 10000}   \n",
       "10        knn    tfidf                         {'vect__lowercase': False}   \n",
       "11        knn    tfidf                    {'vect__stop_words': 'english'}   \n",
       "12        knn    tfidf  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "13        knn    tfidf  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "14        knn    tfidf                      {'vect__max_features': 10000}   \n",
       "15         nb   counts                         {'vect__lowercase': False}   \n",
       "16         nb   counts                    {'vect__stop_words': 'english'}   \n",
       "17         nb   counts  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "18         nb   counts  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "19         nb   counts                      {'vect__max_features': 10000}   \n",
       "20         nb       tf                          {'vect__lowercase': True}   \n",
       "21         nb       tf                    {'vect__stop_words': 'english'}   \n",
       "22         nb       tf  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "23         nb       tf  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "24         nb       tf                      {'vect__max_features': 10000}   \n",
       "25         nb    tfidf                         {'vect__lowercase': False}   \n",
       "26         nb    tfidf                         {'vect__stop_words': None}   \n",
       "27         nb    tfidf  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "28         nb    tfidf  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "29         nb    tfidf                      {'vect__max_features': 10000}   \n",
       "30       sgdc   counts                          {'vect__lowercase': True}   \n",
       "31       sgdc   counts                    {'vect__stop_words': 'english'}   \n",
       "32       sgdc   counts  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "33       sgdc   counts  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "34       sgdc   counts                      {'vect__max_features': 10000}   \n",
       "35       sgdc       tf                         {'vect__lowercase': False}   \n",
       "36       sgdc       tf                    {'vect__stop_words': 'english'}   \n",
       "37       sgdc       tf  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "38       sgdc       tf  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "39       sgdc       tf                      {'vect__max_features': 10000}   \n",
       "40       sgdc    tfidf                          {'vect__lowercase': True}   \n",
       "41       sgdc    tfidf                         {'vect__stop_words': None}   \n",
       "42       sgdc    tfidf  {'vect__analyzer': 'word', 'vect__ngram_range'...   \n",
       "43       sgdc    tfidf  {'vect__analyzer': 'char', 'vect__ngram_range'...   \n",
       "44       sgdc    tfidf                      {'vect__max_features': 10000}   \n",
       "\n",
       "    Mean Accuracy  Precision  Recall     F1  \n",
       "0           0.352      0.421   0.352  0.357  \n",
       "1           0.364      0.567   0.364  0.401  \n",
       "2           0.352      0.421   0.352  0.357  \n",
       "3           0.394      0.435   0.394  0.399  \n",
       "4           0.353      0.408   0.353  0.361  \n",
       "5           0.408      0.489   0.408  0.417  \n",
       "6           0.624      0.637   0.624  0.626  \n",
       "7           0.514      0.553   0.514  0.519  \n",
       "8           0.442      0.513   0.442  0.453  \n",
       "9           0.413      0.478   0.413  0.421  \n",
       "10          0.657      0.671   0.657  0.657  \n",
       "11          0.676      0.685   0.676  0.676  \n",
       "12          0.659      0.674   0.659  0.660  \n",
       "13          0.559      0.590   0.559  0.565  \n",
       "14          0.638      0.653   0.638  0.640  \n",
       "15          0.799      0.810   0.799  0.789  \n",
       "16          0.796      0.804   0.796  0.785  \n",
       "17          0.816      0.827   0.816  0.810  \n",
       "18          0.778      0.793   0.778  0.766  \n",
       "19          0.757      0.746   0.757  0.740  \n",
       "20          0.833      0.834   0.833  0.831  \n",
       "21          0.832      0.833   0.832  0.831  \n",
       "22          0.835      0.837   0.835  0.834  \n",
       "23          0.812      0.816   0.812  0.810  \n",
       "24          0.807      0.808   0.807  0.805  \n",
       "25          0.837      0.838   0.837  0.835  \n",
       "26          0.835      0.836   0.835  0.834  \n",
       "27          0.834      0.837   0.834  0.833  \n",
       "28          0.805      0.809   0.805  0.802  \n",
       "29          0.811      0.812   0.811  0.810  \n",
       "30          0.810      0.817   0.810  0.809  \n",
       "31          0.827      0.829   0.827  0.825  \n",
       "32          0.820      0.823   0.820  0.817  \n",
       "33          0.770      0.776   0.770  0.771  \n",
       "34          0.793      0.802   0.793  0.792  \n",
       "35          0.810      0.810   0.810  0.807  \n",
       "36          0.832      0.833   0.832  0.830  \n",
       "37          0.826      0.827   0.826  0.823  \n",
       "38          0.806      0.806   0.806  0.802  \n",
       "39          0.792      0.795   0.792  0.787  \n",
       "40          0.854      0.855   0.854  0.852  \n",
       "41          0.852      0.853   0.852  0.851  \n",
       "42          0.857      0.858   0.857  0.855  \n",
       "43          0.844      0.844   0.844  0.842  \n",
       "44          0.828      0.828   0.828  0.826  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prf_params = []\n",
    "mean_acc_params = []\n",
    "classifier_names = []\n",
    "feature_names = []\n",
    "vect_params = []\n",
    "\n",
    "all_cv_results_params = []\n",
    "\n",
    "for key, pipe in tqdm(best_pipelines.items()):\n",
    "    for params in parameters:\n",
    "        gs_clf = GridSearchCV(pipe, params, cv=5, n_jobs=-1)\n",
    "        gs_clf.fit(twenty_train.data, twenty_train.target)\n",
    "        predicted = gs_clf.predict(twenty_test.data)\n",
    "\n",
    "        mean_acc = np.mean(predicted == twenty_test.target)\n",
    "        mean_acc_params.append(mean_acc)\n",
    "        prf = metrics.precision_recall_fscore_support(twenty_test.target, predicted, average='weighted')\n",
    "        prf_params.append(prf)\n",
    "\n",
    "        vect_params.append(gs_clf.best_params_)\n",
    "        best_estimator = gs_clf.best_estimator_\n",
    "        classifier_names.append(key[0])\n",
    "        feature_names.append(key[1])\n",
    "\n",
    "        all_cv_results_params.append(gs_clf.cv_results_)\n",
    "\n",
    "df_data = {\"Classifier\": classifier_names,\n",
    "            \"Features\": feature_names,\n",
    "            \"Vectorizer Parameters\": vect_params,\n",
    "            \"Mean Accuracy\": mean_acc_params\n",
    "          }\n",
    "results_exp3 = pd.DataFrame(df_data)\n",
    "prf_params_df = pd.DataFrame(prf_params, columns=[\"Precision\", \"Recall\", \"F1\", \"_\"]).drop(columns=['_'])\n",
    "results_exp3 = results_exp3.merge(prf_params_df, left_index=True, right_index=True)\n",
    "results_exp3 = results_exp3.round(3)\n",
    "results_exp3.to_csv('results/experiment3_knn.csv')\n",
    "results_exp3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "13df7030f0a293fc7b224c8674413bb1891143c2877d2001af36e74cd2d7cc9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
